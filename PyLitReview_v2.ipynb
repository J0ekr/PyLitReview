{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements:\n",
    "\n",
    "- https://selenium-python.readthedocs.io/locating-elements.html\n",
    "- https://sites.google.com/a/chromium.org/chromedriver/downloads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from html.parser import HTMLParser\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from pybtex.database.input import bibtex\n",
    "import pybtex.errors\n",
    "pybtex.errors.set_strict_mode(False)\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "from itertools import permutations \n",
    "\n",
    "import os\n",
    "import time\n",
    "import config\n",
    "from enum import Enum\n",
    "\n",
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for IEEE\n",
    "UNI_MAIL = config.UNI_MAIL\n",
    "UNI_PWD = config.UNI_PWD\n",
    "UNI_USER = config.UNI_USER\n",
    "\n",
    "# Needed for ScienceDirect\n",
    "ScienceDirect_MAIL = config.ScienceDirect_MAIL\n",
    "ScienceDirect_PWD = config.ScienceDirect_PWD\n",
    "\n",
    "IEEE_bib_files = []\n",
    "\n",
    "# 0: No Screenshots\n",
    "# 1: One Screenshot for each query (recommended)\n",
    "# 2: Screenshots of different steps to find out why crawler might not work\n",
    "DEBUG = 2\n",
    "\n",
    "ieee_maxpage = math.inf\n",
    "acm_maxpage = 39\n",
    "sd_maxpage = 19\n",
    "\n",
    "GLOBAL_ERROR_LIST = []\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for crawling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchWhere(Enum):\n",
    "        Title = 1\n",
    "        Abstract = 2\n",
    "        TitleAbstract = 3 #Keywords have to be in Title OR Abstract\n",
    "        Text = 4\n",
    "class Library(Enum):\n",
    "        IEEE = 1\n",
    "        ACM = 2\n",
    "        ScienceDirect = 3\n",
    "\n",
    "year_min = 1900 # Set to earliest year which should be crawled\n",
    "year_max = 2022 # Set to latest year whichh should be crawled\n",
    "\n",
    "# Search Keyword combinations\n",
    "pres = ['selection',  'pointing', 'interaction']\n",
    "\n",
    "\n",
    "env_pres = ['virtual', 'augmented', 'mixed', 'immersive', '3D'] \n",
    "env_sufs = ['environment', 'reality']\n",
    "keywords = list(itertools.product(pres, env_pres, env_sufs))  + list(itertools.product(pres, ['VR', 'AR', 'MR']))\n",
    "\n",
    "# Keywords should be a list of lists of strings. \n",
    "# The strings will be connected with AND for the search query.\n",
    "keywords = [list(item) for item in keywords]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for crawler\n",
    "\n",
    "## function to crawl: crawl(keywords, LIBRARY, titlesearch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths for dl-folders (dl) to folders for each library [line 9,11,13]\n",
    "def setupCrawler(dl_folder):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('window-size=1920,1080')\n",
    "    \n",
    "    dl = config.downloadfolder_default\n",
    "    if dl_folder == Library.ACM:\n",
    "        dl = config.downloadfolder_acm\n",
    "        options.add_argument('headless')\n",
    "        options.add_argument(\"disable-gpu\")\n",
    "    elif dl_folder == Library.IEEE:\n",
    "        dl = config.downloadfolder_ieee\n",
    "        options.add_argument('headless')\n",
    "        options.add_argument(\"disable-gpu\")\n",
    "    elif dl_folder == Library.ScienceDirect:\n",
    "        dl = config.downloadfolder_sd\n",
    "    p = {\"download.default_directory\": dl}\n",
    "    options.add_experimental_option(\"prefs\", p)\n",
    "    ser = Service(\"./chromedriver.exe\")\n",
    "    op = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=ser, options=options)\n",
    "    print(\"Driver setup complete.\")\n",
    "    return driver\n",
    "\n",
    "def crawl(keywords_list, library, searchWhere):\n",
    "    print(f\"Start crawling {library}\")\n",
    "    if library == Library.ACM:\n",
    "        keywords = [[item.replace(\" \", \"+\") for item in keywords] for keywords in keywords_list]\n",
    "        saveACMBib(keywords, Library.ACM, searchWhere)\n",
    "    elif library == Library.IEEE:\n",
    "        keywords = [[item.replace(\" \", \"%20\") for item in keywords] for keywords in keywords_list]\n",
    "        saveIEEEBib(keywords, Library.IEEE, searchWhere)\n",
    "    elif library == Library.ScienceDirect:\n",
    "        keywords = [[item.replace(\" \", \"%20\") for item in keywords] for keywords in keywords_list]\n",
    "        saveScienceDirectBib(keywords, Library.ScienceDirect, searchWhere)\n",
    "    else:\n",
    "        print(f\"Library {library} not yet supported\")\n",
    "# Goal: keywords, lib, searchWhere(tit, titAbs, text)\n",
    "def getIEEEkey(keywords, kind):\n",
    "    titAbsDict = {\"t\": \"Document%20Title\", \"a\": \"Abstract\"}\n",
    "    key = \"(\"\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        key += f'\"{titAbsDict[kind]}\":\"{keyword}\"'\n",
    "        if (i < len(keywords)-1):\n",
    "            key += \"+AND+\"\n",
    "        else:\n",
    "            key += \")\"\n",
    "    return key\n",
    "def getURL(keywords, library, searchWhere, concatentation=\"AND\"):\n",
    "    URL = \"\"\n",
    "    search = \"\"\n",
    "    if library == Library.ACM:\n",
    "        titleSearch = \"doSearch?AllField=\"\n",
    "        for i, keyword in enumerate(keywords):\n",
    "            search += f\"%22{keyword}%22\"\n",
    "            if (i < len(keywords)-1):\n",
    "                search += f\"+{concatentation}+\"\n",
    "        match searchWhere:\n",
    "            case SearchWhere.Title:\n",
    "                print(\"Searching ACM for title only\")\n",
    "                titleSearch = f\"doSearch?fillQuickSearch=false&expand=dl&field1=Title&text1={search}\"\n",
    "            case SearchWhere.Abstract:\n",
    "                print(\"Searching ACM for abstract only\")\n",
    "                titleSearch = f\"doSearch?fillQuickSearch=false&expand=dl&field1=Abstract&text1={search}\"\n",
    "            case SearchWhere.TitleAbstract:\n",
    "                print(\"ACM does not support searching for keywords in Title OR Abstract. Please use Title and Abstract search seperately.\")\n",
    "            case SearchWhere.Text | _:\n",
    "                print(\"Quicksearching ACM\")\n",
    "        URL = f\"https://dl.acm.org/action/{titleSearch}&pageSize=50&AfterYear={year_min}&BeforeYear={year_max}&startPage=\"\n",
    "        return URL\n",
    "    elif library == Library.IEEE:\n",
    "        titleSearch = \"doSearch?AllField=\"\n",
    "        match searchWhere:\n",
    "            case SearchWhere.Title:\n",
    "                print(\"Searching IEEE for title only\")\n",
    "                search = getIEEEkey(keywords, \"t\")\n",
    "            case SearchWhere.TitleAbstract:\n",
    "                print(\"Searching IEEE for title or abstract\")\n",
    "                search = getIEEEkey(keywords, \"t\")\n",
    "                search += \"+%20OR%20+\"\n",
    "                search += getIEEEkey(keywords, \"a\")\n",
    "            case SearchWhere.Abstract:\n",
    "                print(\"Searching IEEE for abstract only\")\n",
    "                search = getIEEEkey(keywords, \"a\")\n",
    "            case SearchWhere.Text | _:\n",
    "                print(\"Quicksearching IEEE for fulltext (not recommended)\")\n",
    "                for i, keyword in enumerate(keywords):\n",
    "                    key = f\"%22{keyword}%22\"\n",
    "                    search += key\n",
    "                    if (i < len(keywords)-1):\n",
    "                        search += f\"+{concatentation}+\"\n",
    "        URL = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?&queryText={search}&highlight=true&returnFacets=ALL&returnType=SEARCH&matchPubs=true&ranges={year_min}_{year_max}_Year&rowsPerPage=50&pageNumber=\"\n",
    "        return URL\n",
    "    elif library == Library.ScienceDirect:\n",
    "        titleSearch = \"tak=\"\n",
    "        if searchWhere == SearchWhere.Title:\n",
    "            titleSearch = \"title=\"\n",
    "        elif searchWhere == SearchWhere.TitleAbstract:\n",
    "            titleSearch = \"tak=\"\n",
    "        for i, keyword in enumerate(keywords):\n",
    "            search += f\"%22{keyword}%22\"\n",
    "            if (i < len(keywords)-1):\n",
    "                search += f\"%20{concatentation}%20\" \n",
    "        URL = f\"https://www.sciencedirect.com/search?date={year_min}-{year_max}&{titleSearch}{search}&show=50&offset=\"\n",
    "        print(URL)\n",
    "        return URL\n",
    "    else:\n",
    "        print(f\"Library {library} not yet supported\")\n",
    "    return URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIEEEBib (toOpen, driver):\n",
    "    driver.get(toOpen)\n",
    "    time.sleep(30)\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"main-section\").find_elements(by=By.XPATH, value=\".//*\")[5].click() #Click SELECT ALL\n",
    "    time.sleep(5)\n",
    "    \n",
    "    export = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[10] # Find EXPORT\n",
    "    if \"Export\" not in export.text:\n",
    "        export = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[20] # Find EXPORT\n",
    "    export.click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"tooltip-inner\").find_elements(by=By.XPATH, value=\".//*\")[4].click() # CLick Citations\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    if DEBUG > 1: driver.save_screenshot(\"preBibTex.png\")\n",
    "    bibText_locator = driver.find_elements(By.NAME, \"download-format\")[1]\n",
    "    \n",
    "    bibText_locator.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    citAbs_locator = driver.find_elements(By.NAME, \"citations-format\")[1]\n",
    "    \n",
    "    citAbs_locator.click()\n",
    "    if DEBUG > 1: driver.save_screenshot(\"postCitAbs.png\")\n",
    "    tooltip_inner = driver.find_element(by=By.CLASS_NAME, value=\"tooltip-inner\")\n",
    "    export_locator = tooltip_inner.find_elements(by=By.XPATH, value=\".//*\")[-1]\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    curWindowHndl = driver.current_window_handle\n",
    "    assert len(driver.window_handles) == 1\n",
    "    export_locator.send_keys(Keys.CONTROL + Keys.ENTER) #open link in new tab keyboard shortcut\n",
    "    time.sleep(10)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"ieee_dl.png\")\n",
    "\n",
    "    for window_handle in driver.window_handles:\n",
    "        if window_handle != curWindowHndl:\n",
    "            driver.switch_to.window(window_handle)\n",
    "            break\n",
    "    \n",
    "    time.sleep(10) #wait until new tab finishes loading\n",
    "\n",
    "    driver.switch_to.window(driver.window_handles[1]) #assuming new tab is at index 1\n",
    "    \n",
    "    bib = driver.find_element(by=By.XPATH, value=\"/html/body\").text\n",
    "    time.sleep(2)\n",
    "    driver.close() #closes new tab\n",
    "    driver.switch_to.window(curWindowHndl)\n",
    "    time.sleep(20)\n",
    "    return bib\n",
    "\n",
    "def saveIEEEBib(keywords_list, dl_folder, searchWhere=SearchWhere.Text):\n",
    "    driver = setupCrawler(dl_folder)\n",
    "    # bib_datas = []\n",
    "    # glob_bib = \"\"\n",
    "    for keywords in keywords_list:\n",
    "        print(f\"Search for: {keywords}\")\n",
    "        IEEE_URL = getURL(keywords, Library.IEEE, searchWhere)\n",
    "        driver.get(IEEE_URL)#put here the adress of your page\n",
    "        \n",
    "        print(IEEE_URL)\n",
    "        time.sleep(7)\n",
    "        name = \"\"\n",
    "        for word in keywords:\n",
    "            name += f\"{word}\"\n",
    "        if searchWhere == SearchWhere.Title:\n",
    "            name += \"_Title\"\n",
    "        elif searchWhere == SearchWhere.TitleAbstract:\n",
    "            name += \"_TitleAbstract\"\n",
    "        if DEBUG > 0: driver.save_screenshot(f\"IEEE_{name}.png\")\n",
    "        try:\n",
    "            results = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[31]\n",
    "            if results.text == \"Set Search Alerts\":\n",
    "                results = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[41]\n",
    "            results = results.text.split(\" \")[0].split(\"-\")[-1]\n",
    "            if \",\" in results:\n",
    "                results = results.replace(\",\", \"\")\n",
    "        except NoSuchElementException:\n",
    "            results = 0\n",
    "        except IndexError:\n",
    "            results = 0\n",
    "        if results == \"\":\n",
    "            results = 0\n",
    "        \n",
    "        results = int(results)\n",
    "        r = int(np.min([math.ceil(results / 50), ieee_maxpage]))\n",
    "\n",
    "        for i in tqdm.tqdm(range(r)):\n",
    "            toOpen = IEEE_URL + str(i+1)\n",
    "\n",
    "            bib = loadIEEEBib(toOpen, driver)\n",
    "\n",
    "            bib_data = bibtexparser.loads(bib)\n",
    "            try:\n",
    "                with open(f\"./ieee/ieee_{name.replace('*', '')}_page{i}.bib\", 'w', encoding=\"utf-8\") as bibtex_file:\n",
    "                    bibtexparser.dump(bib_data, bibtex_file)\n",
    "            except:\n",
    "                print(f\"Something went wrong while saving: {name}_{i}\") \n",
    "                urls.append((f\"./ieee/ieee_{name.replace('*', '')}_page{i}.bib\", toOpen))\n",
    "\n",
    "            time.sleep(3)\n",
    "    #Write Filename and Link of files with broken bib file into ERRORS.txt\n",
    "    # These files have to be manually downloaded / fixed\n",
    "    with open(f\"./ieee/ERRORS.txt\", 'w') as error_file:\n",
    "        for url in urls:\n",
    "            error_file.write(url[0])\n",
    "            error_file.write(\" | \")\n",
    "            error_file.write(url[1])\n",
    "            error_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl(ieee_keywords, Library.IEEE, SearchWhere.TitleAbstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./ieee/ERRORS.txt\", 'w') as error_file:\n",
    "    for url in urls:\n",
    "        error_file.write(url[0])\n",
    "        error_file.write(\" | \")\n",
    "        error_file.write(url[1])\n",
    "        error_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadACMBib (toOpen, driver):\n",
    "    driver.get(toOpen)#put here the adress of your page\n",
    "    # delay = 3 # seconds\n",
    "    #iterate over middle navbar to see if query found paper results or only people\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"item-results__checkbox\").click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"item-results__buttons.visible\").find_elements(by=By.XPATH, value=\".//*\")[0].click()\n",
    "    time.sleep(20)\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"rlist--inline.separator\").find_elements(by=By.XPATH, value=\".//*\")[1].click()\n",
    "    time.sleep(20)\n",
    "def saveACMBib(keywords_list, dl_folder, searchWhere = SearchWhere.Text):\n",
    "    driver = setupCrawler(dl_folder)\n",
    "    for keywords in keywords_list:\n",
    "        print(f\"Search for: {keywords}\")\n",
    "        ACM_URL = getURL(keywords, Library.ACM, searchWhere)\n",
    "        if DEBUG > 0: print(ACM_URL)\n",
    "        driver.get(ACM_URL)#put here the adress of your page\n",
    "        time.sleep(3)\n",
    "        navbar = driver.find_elements(by=By.CLASS_NAME, value=\"search-result__nav-container\")\n",
    "        navbar = navbar[0]\n",
    "        navelements = navbar.find_elements(by=By.XPATH, value=\".//*\")\n",
    "        foundResults = False\n",
    "        for nav_element in navelements:\n",
    "            if \"RESULTS\" in nav_element.text: \n",
    "                foundResults = True\n",
    "        if foundResults == False: \n",
    "            print(\"Only people in results - next keyword\")\n",
    "            continue\n",
    "        name = \"\"\n",
    "        for word in keywords:\n",
    "            name += f\"{word}\"\n",
    "        match searchWhere:\n",
    "            case SearchWhere.Title:\n",
    "                name += \"_TitleOnly\" \n",
    "            case SearchWhere.Abstract:\n",
    "                name += \"_AbstractOnly\" \n",
    "            case SearchWhere.TitleAbstract:\n",
    "                print(\"Stopping\")\n",
    "                break \n",
    "                # name += \"_TitleAbstract\"\n",
    "            case SearchWhere.Text | _:\n",
    "                name += \"\"  \n",
    "        if DEBUG > 0: driver.save_screenshot(f\"./acm_{name}.png\")\n",
    "        # get amount of results for for-loop\n",
    "\n",
    "        try:\n",
    "            results = driver.find_element(by=By.CLASS_NAME, value=\"result__count\")\n",
    "            results = results.text.split(\" \")[0]\n",
    "            if \",\" in results:\n",
    "                results = results.replace(\",\", \"\")\n",
    "            results = int(results)\n",
    "        except NoSuchElementException:\n",
    "            results = 0\n",
    "        r = np.min([math.ceil(results / 50), acm_maxpage])\n",
    "        # Loop through all pages and save resulting bib files\n",
    "        for i in tqdm.tqdm(range(r)):\n",
    "            toOpen = ACM_URL + str(i)\n",
    "            # driver = setupCrawler(dl_folder) # I think this is unnecessary - if something breaks with ACM try uncommenting this line first\n",
    "            loadACMBib(toOpen, driver)\n",
    "            try:\n",
    "                os.rename('./acm/acm.bib', f'./acm/acm_{name.replace(\"*\",\"\")}_page{i}.bib')\n",
    "            except FileNotFoundError:\n",
    "                print(\"Only 1 bib entry in that file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl(keywords, Library.ACM, SearchWhere.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl(keywords, Library.ACM, SearchWhere.Abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScienceDirect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loginScienceDirect(driver):\n",
    "    Login_URL = \"https://www.sciencedirect.com/\"\n",
    "    driver.get(Login_URL)\n",
    "    time.sleep(5)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"init.png\")\n",
    "    driver.find_element(by=By.LINK_TEXT, value=\"Sign in\").click()\n",
    "    time.sleep(10)\n",
    "    mail = driver.find_element(by=By.ID, value=\"bdd-email\")\n",
    "    mail.send_keys(UNI_MAIL)\n",
    "    time.sleep(1)\n",
    "    mail.send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"login.png\")\n",
    "    time.sleep(1)\n",
    "    driver.find_element(by=By.ID, value=\"bdd-elsPrimaryBtn\").click()\n",
    "    time.sleep(1)\n",
    "    driver.find_element(by=By.ID, value=\"username\").send_keys(UNI_USER)\n",
    "    time.sleep(1)\n",
    "    pwd = driver.find_element(by=By.ID, value=\"password\")\n",
    "    pwd.send_keys(UNI_PWD)\n",
    "    time.sleep(1)\n",
    "    pwd.send_keys(Keys.ENTER)\n",
    "    time.sleep(2)\n",
    "    # attemps = 0\n",
    "    try:\n",
    "        driver.find_element(by=By.ID, value=\"institution-button\").click()\n",
    "    except:\n",
    "        print(\"intitution button apparently no accessable\")\n",
    "        driver.save_screenshot(\"StaleElement.png\")\n",
    "        driver.find_element(by=By.ID, value=\"institution-button\").click()\n",
    "    time.sleep(2)\n",
    "    return driver\n",
    "def loadScienceDirectBib(toOpen, driver):\n",
    "    driver.get(toOpen)\n",
    "    time.sleep(5)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"sciencedirect.png\")\n",
    "    driver.find_element(by=By.ID, value=\"select-all-results\").click()\n",
    "    time.sleep(1)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"sciencedirect_clickall.png\")\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"button-link.export-all-link-button.button-link-primary\").click()\n",
    "    time.sleep(5)\n",
    "    driver.find_elements(by=By.CLASS_NAME, value=\"button-link.button-link-primary.export-option.u-display-block\")[2].click()\n",
    "    time.sleep(10)\n",
    "def saveScienceDirectBib(keywords_list, dl_folder, titleOnly):\n",
    "    driver = setupCrawler(dl_folder)\n",
    "    SD_URL = getURL(keywords_list[0], Library.ScienceDirect, titleOnly)\n",
    "    driver.get('https://www.sciencedirect.com/')\n",
    "    if DEBUG > 1: driver.save_screenshot(\"SD.png\")\n",
    "    try:\n",
    "        driver = loginScienceDirect(driver)\n",
    "    except NoSuchElementException:\n",
    "        print(\"Already logged in or wrong credentials\") \n",
    "    # loginScienceDirect(driver)\n",
    "    if DEBUG > 1: driver.save_screenshot(f\"{SD_URL}.png\")\n",
    "    for keywords in keywords_list:\n",
    "        print(f\"Search for: {keywords}\")\n",
    "        SD_URL = getURL(keywords, Library.ScienceDirect, titleOnly)\n",
    "        driver.get(SD_URL)#put here the adress of your page\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            results = driver.find_element(by=By.CLASS_NAME, value=\"search-body-results-text\")\n",
    "            results = results.text.split(\" \")[0]\n",
    "            if \",\" in results:\n",
    "                results = results.replace(\",\", \"\")\n",
    "            results = int(results)\n",
    "        except NoSuchElementException:\n",
    "            results = 0\n",
    "        \n",
    "        r = np.min([math.ceil(results / 50), sd_maxpage])\n",
    "        for i in tqdm.tqdm(range(r)):\n",
    "            # driver = setupCrawler(dl_folder)\n",
    "            toOpen = SD_URL + str(i*50)\n",
    "            loadScienceDirectBib(toOpen, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords\n",
    "sd_keywords = keywords[-3:]\n",
    "# ['pointing', 'virtual', 'environment']\n",
    "# ['interaction', 'augmented', 'environment']\n",
    "\n",
    "sd_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl(sd_keywords, Library.ScienceDirect, SearchWhere.TitleAbstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6532684ccaeb1bcbbe852b7f75c67e6f1d55df7d386020fd37670376cbe3d2c9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

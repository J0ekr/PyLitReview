{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements:\n",
    "\n",
    "- https://selenium-python.readthedocs.io/locating-elements.html\n",
    "- https://sites.google.com/a/chromium.org/chromedriver/downloads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from html.parser import HTMLParser\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "from pybtex.database.input import bibtex\n",
    "import pybtex.errors\n",
    "pybtex.errors.set_strict_mode(False)\n",
    "\n",
    "\n",
    "\n",
    "import itertools\n",
    "from itertools import permutations \n",
    "\n",
    "import os\n",
    "import time\n",
    "import config\n",
    "\n",
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for IEEE\n",
    "UNI_MAIL = config.UNI_MAIL\n",
    "UNI_PWD = config.UNI_PWD\n",
    "UNI_USER = config.UNI_USER\n",
    "\n",
    "# Needed for ScienceDirect\n",
    "ScienceDirect_MAIL = config.ScienceDirect_MAIL\n",
    "ScienceDirect_PWD = config.ScienceDirect_PWD\n",
    "\n",
    "IEEE_bib_files = []\n",
    "\n",
    "# 0: No Screenshots\n",
    "# 1: One Screenshot for each query (recommended)\n",
    "# 2: Screenshots of different steps to find out why crawler might not work\n",
    "DEBUG = 2\n",
    "\n",
    "ieee_maxpage = math.inf\n",
    "acm_maxpage = 39\n",
    "sd_maxpage = 19\n",
    "\n",
    "GLOBAL_ERROR_LIST = []\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for crawling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"tit\": Title only, \n",
    "# \"titAbs\": Title and Abstract, \n",
    "# \"text\": Full text / quicksearch - not fully tested\n",
    "from enum import Enum\n",
    "class SearchWhere(Enum):\n",
    "        Title = 1\n",
    "        Abstract = 2\n",
    "        TitleAbstract = 3\n",
    "        Text = 4\n",
    "sw = SearchWhere\n",
    "\n",
    "year_min = 1900 # Set to earliest year which should be crawled\n",
    "year_max = 2022 # Set to latest year whichh should be crawled\n",
    "\n",
    "LIBS = [\"ScienceDirect\", \"ACM\", \"IEEE\"]\n",
    "\n",
    "# Search Keyword combinations\n",
    "pres = [\n",
    "    'selection',  'pointing'\n",
    "        ]\n",
    "sufs = ['virtual'\n",
    "        ]\n",
    "keywords = list(itertools.product(pres, sufs))\n",
    "# Keywords should be a list of lists of strings. \n",
    "# The strings will be connected with AND for the search query.\n",
    "keywords = [list(item) for item in keywords]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for crawler\n",
    "\n",
    "## function to crawl: crawl(keywords, LIBRARY, titlesearch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths for dl-folders (dl) to folders for each library [line 9,11,13]\n",
    "def setupCrawler(dl_folder):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('window-size=1920,1080')\n",
    "    \n",
    "    dl = config.downloadfolder_default\n",
    "    if dl_folder == \"acm\":\n",
    "        dl = config.downloadfolder_acm\n",
    "        options.add_argument('headless')\n",
    "        options.add_argument(\"disable-gpu\")\n",
    "    elif dl_folder == \"ieee\":\n",
    "        dl = config.downloadfolder_ieee\n",
    "        options.add_argument('headless')\n",
    "        options.add_argument(\"disable-gpu\")\n",
    "    elif dl_folder == \"sd\":\n",
    "        dl = config.downloadfolder_sd\n",
    "    p = {\"download.default_directory\": dl}\n",
    "    options.add_experimental_option(\"prefs\", p)\n",
    "    driver = webdriver.Chrome(executable_path = \"./chromedriver.exe\", options=options)\n",
    "    print(\"Driver setup complete.\")\n",
    "    return driver\n",
    "# Method to crawl one single library: Keywords: [], library: String, title: bool, dl_folder: string\n",
    "def crawl(keywords_list, library, searchWhere):\n",
    "    print(f\"Start crawling {library}\")\n",
    "    if library == \"ACM\":\n",
    "        keywords = [[item.replace(\" \", \"+\") for item in keywords] for keywords in keywords_list]\n",
    "        saveACMBib(keywords, \"acm\", searchWhere)\n",
    "    elif library == \"IEEE\":\n",
    "        keywords = [[item.replace(\" \", \"%20\") for item in keywords] for keywords in keywords_list]\n",
    "        saveIEEEBib(keywords, \"ieee\", searchWhere)\n",
    "    elif library == \"ScienceDirect\":\n",
    "        keywords = [[item.replace(\" \", \"%20\") for item in keywords] for keywords in keywords_list]\n",
    "        saveScienceDirectBib(keywords, \"sd\", searchWhere)\n",
    "    else:\n",
    "        print(f\"Library {library} not yet supported\")\n",
    "# Goal: keywords, lib, searchWhere(tit, titAbs, text)\n",
    "def getIEEEkey(keywords, kind):\n",
    "    titAbsDict = {\"t\": \"Document%20Title\", \"a\": \"Abstract\"}\n",
    "    key = \"(\"\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        key += f'\"{titAbsDict[kind]}\":\"{keyword}\"'\n",
    "        if (i < len(keywords)-1):\n",
    "            key += \"+AND+\"\n",
    "        else:\n",
    "            key += \")\"\n",
    "    return key\n",
    "def getURL(keywords, library, searchWhere, concatentation=\"AND\"):\n",
    "    URL = \"\"\n",
    "    search = \"\"\n",
    "    if library == \"ACM\":\n",
    "        titleSearch = \"doSearch?AllField=\"\n",
    "        for i, keyword in enumerate(keywords):\n",
    "            search += f\"%22{keyword}%22\"\n",
    "            if (i < len(keywords)-1):\n",
    "                search += f\"+{concatentation}+\"\n",
    "        if searchWhere == SearchWhere.Title:\n",
    "            print(\"Searching ACM for title only\")\n",
    "            titleSearch = f\"doSearch?fillQuickSearch=false&expand=dl&field1=Title&text1={search}\"\n",
    "        elif searchWhere == SearchWhere.TitleAbstract:\n",
    "            print(\"Searching ACM for title and abstract\")\n",
    "            titleSearch = f\"doSearch?fillQuickSearch=false&expand=dl&field1=Title&text1={search}&field2=Abstract&text2={search}\"\n",
    "        else:\n",
    "            print(\"Quicksearching ACM\")\n",
    "        URL = f\"https://dl.acm.org/action/{titleSearch}&pageSize=50&AfterYear={year_min}&BeforeYear={year_max}&startPage=\"\n",
    "        return URL\n",
    "    elif library == \"IEEE\":\n",
    "        titleSearch = \"doSearch?AllField=\"\n",
    "        match searchWhere:\n",
    "            case SearchWhere.Title:\n",
    "                print(\"Searching IEEE for title only\")\n",
    "                search = getIEEEkey(keywords, \"t\")\n",
    "            case SearchWhere.TitleAbstract:\n",
    "                print(\"Searching IEEE for title or abstract\")\n",
    "                search = getIEEEkey(keywords, \"t\")\n",
    "                search += \"+%20OR%20+\"\n",
    "                search += getIEEEkey(keywords, \"a\")\n",
    "            case SearchWhere.Abstract:\n",
    "                print(\"Searching IEEE for abstract only\")\n",
    "                search = getIEEEkey(keywords, \"a\")\n",
    "            case SearchWhere.Text | _:\n",
    "                print(\"Quicksearching IEEE for fulltext (not recommended)\")\n",
    "                for i, keyword in enumerate(keywords):\n",
    "                    key = f\"%22{keyword}%22\"\n",
    "                    search += key\n",
    "                    if (i < len(keywords)-1):\n",
    "                        search += f\"+{concatentation}+\"\n",
    "        URL = f\"https://ieeexplore.ieee.org/search/searchresult.jsp?&queryText={search}&highlight=true&returnFacets=ALL&returnType=SEARCH&matchPubs=true&ranges={year_min}_{year_max}_Year&rowsPerPage=50&pageNumber=\"\n",
    "        return URL\n",
    "    elif library == \"ScienceDirect\":\n",
    "        titleSearch = \"tak=\"\n",
    "        if searchWhere == SearchWhere.Title:\n",
    "            titleSearch = \"title=\"\n",
    "        elif searchWhere == SearchWhere.TitleAbstract:\n",
    "            titleSearch = \"tak=\"\n",
    "        for i, keyword in enumerate(keywords):\n",
    "            search += f\"%22{keyword}%22\"\n",
    "            if (i < len(keywords)-1):\n",
    "                search += f\"%20{concatentation}%20\" \n",
    "        URL = f\"https://www.sciencedirect.com/search?date={year_min}-{year_max}&{titleSearch}{search}&show=50&offset=\"\n",
    "        print(URL)\n",
    "        return URL\n",
    "    else:\n",
    "        print(f\"Library {library} not yet supported\")\n",
    "    return URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIEEEBib (toOpen, driver):\n",
    "    driver.get(toOpen)\n",
    "    time.sleep(25)\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"main-section\").find_elements(by=By.XPATH, value=\".//*\")[5].click() #Click SELECT ALL\n",
    "    time.sleep(5)\n",
    "    \n",
    "    export = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[10] # Find EXPORT\n",
    "    if \"Export\" not in export.text:\n",
    "        export = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[20] # Find EXPORT\n",
    "    export.click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element(by=By.CLASS_NAME, value=\"tooltip-inner\").find_elements(by=By.XPATH, value=\".//*\")[4].click() # CLick Citations\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    if DEBUG > 1: driver.save_screenshot(\"preBibTex.png\")\n",
    "    bibText_locator = driver.find_elements(By.NAME, \"download-format\")[1]\n",
    "    \n",
    "    bibText_locator.click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    citAbs_locator = driver.find_elements(By.NAME, \"citations-format\")[1]\n",
    "    \n",
    "    citAbs_locator.click()\n",
    "    if DEBUG > 1: driver.save_screenshot(\"postCitAbs.png\")\n",
    "    tooltip_inner = driver.find_element(by=By.CLASS_NAME, value=\"tooltip-inner\")\n",
    "    export_locator = tooltip_inner.find_elements(by=By.XPATH, value=\".//*\")[-1]\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    curWindowHndl = driver.current_window_handle\n",
    "    assert len(driver.window_handles) == 1\n",
    "    export_locator.send_keys(Keys.CONTROL + Keys.ENTER) #open link in new tab keyboard shortcut\n",
    "    time.sleep(10)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"ieee_dl.png\")\n",
    "\n",
    "    for window_handle in driver.window_handles:\n",
    "        if window_handle != curWindowHndl:\n",
    "            driver.switch_to.window(window_handle)\n",
    "            break\n",
    "    \n",
    "    time.sleep(10) #wait until new tab finishes loading\n",
    "\n",
    "    driver.switch_to.window(driver.window_handles[1]) #assuming new tab is at index 1\n",
    "    \n",
    "    bib = driver.find_element(by=By.XPATH, value=\"/html/body\").text\n",
    "    time.sleep(2)\n",
    "    driver.close() #closes new tab\n",
    "    driver.switch_to.window(curWindowHndl)\n",
    "    time.sleep(20)\n",
    "    return bib\n",
    "\n",
    "def saveIEEEBib(keywords_list, dl_folder, searchWhere=SearchWhere.Text):\n",
    "    driver = setupCrawler(dl_folder)\n",
    "    # bib_datas = []\n",
    "    # glob_bib = \"\"\n",
    "    for keywords in keywords_list:\n",
    "        print(f\"Search for: {keywords}\")\n",
    "        IEEE_URL = getURL(keywords, \"IEEE\", searchWhere)\n",
    "        driver.get(IEEE_URL)#put here the adress of your page\n",
    "        \n",
    "        print(IEEE_URL)\n",
    "        time.sleep(7)\n",
    "        name = \"\"\n",
    "        for word in keywords:\n",
    "            name += f\"{word}\"\n",
    "        if searchWhere == SearchWhere.Title:\n",
    "            name += \"_Title\"\n",
    "        elif searchWhere == SearchWhere.TitleAbstract:\n",
    "            name += \"_TitleAbstract\"\n",
    "        if DEBUG > 0: driver.save_screenshot(f\"IEEE_{name}.png\")\n",
    "        try:\n",
    "            results = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[31]\n",
    "            if results.text == \"Set Search Alerts\":\n",
    "                results = driver.find_element(by=By.CLASS_NAME, value=\"ng-Dashboard\").find_elements(by=By.XPATH, value=\".//*\")[41]\n",
    "            results = results.text.split(\" \")[0].split(\"-\")[-1]\n",
    "            if \",\" in results:\n",
    "                results = results.replace(\",\", \"\")\n",
    "        except NoSuchElementException:\n",
    "            results = 0\n",
    "        except IndexError:\n",
    "            results = 0\n",
    "        if results == \"\":\n",
    "            results = 0\n",
    "        \n",
    "        results = int(results)\n",
    "        r = int(np.min([math.ceil(results / 50), ieee_maxpage]))\n",
    "\n",
    "        for i in tqdm.tqdm(range(r)):\n",
    "            toOpen = IEEE_URL + str(i+1)\n",
    "\n",
    "            bib = loadIEEEBib(toOpen, driver)\n",
    "            bib_data = bibtexparser.loads(bib)\n",
    "            try:\n",
    "                with open(f\"./ieee/ieee_{name}_page{i}.bib\", 'w') as bibtex_file:\n",
    "                    bibtexparser.dump(bib_data, bibtex_file)\n",
    "            except:\n",
    "                print(f\"Something went wrong while saving: {name}_{i}\") \n",
    "                urls.append((f\"./ieee/ieee_{name}_page{i}.bib\", toOpen))\n",
    "\n",
    "            time.sleep(3)\n",
    "    #Write Filename and Link of files with broken bib file into ERRORS.txt\n",
    "    # These files have to be manually downloaded / fixed\n",
    "    with open(f\"./ieee/ERRORS.txt\", 'w') as error_file:\n",
    "        for url in urls:\n",
    "            error_file.write(url[0])\n",
    "            error_file.write(\" | \")\n",
    "            error_file.write(url[1])\n",
    "            error_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start crawling IEEE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\AppData\\Local\\Temp\\ipykernel_9544\\2698834398.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = \"./chromedriver.exe\", options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver setup complete.\n",
      "Search for: ['distant', 'selection', 'virtual', 'reality']\n",
      "Searching IEEE for title or abstract\n",
      "https://ieeexplore.ieee.org/search/searchresult.jsp?&queryText=(\"Document%20Title\":\"distant\"+AND+\"Document%20Title\":\"selection\"+AND+\"Document%20Title\":\"virtual\"+AND+\"Document%20Title\":\"reality\")+%20OR%20+(\"Abstract\":\"distant\"+AND+\"Abstract\":\"selection\"+AND+\"Abstract\":\"virtual\"+AND+\"Abstract\":\"reality\")&highlight=true&returnFacets=ALL&returnType=SEARCH&matchPubs=true&ranges=1900_2022_Year&rowsPerPage=50&pageNumber=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "crawl([['','selection', 'virtual', 'reality']], \"IEEE\", SearchWhere.TitleAbstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadACMBib (toOpen, driver):\n",
    "    driver.get(toOpen)#put here the adress of your page\n",
    "    # delay = 3 # seconds\n",
    "    driver.find_element_by_class_name(\"item-results__checkbox\").click()\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_class_name(\"item-results__buttons.visible\").find_elements_by_xpath(\".//*\")[0].click()\n",
    "    time.sleep(20)\n",
    "    driver.find_element_by_class_name(\"rlist--inline.separator\").find_elements_by_xpath(\".//*\")[1].click()\n",
    "    time.sleep(20)\n",
    "def saveACMBib(keywords_list, dl_folder, searchWhere = SearchWhere.Text):\n",
    "    driver = setupCrawler(dl_folder)\n",
    "    for keywords in keywords_list:\n",
    "        print(f\"Search for: {keywords}\")\n",
    "        ACM_URL = getURL(keywords, \"ACM\", searchWhere)\n",
    "        driver.get(ACM_URL)#put here the adress of your page\n",
    "        time.sleep(3)\n",
    "        name = \"\"\n",
    "        for word in keywords:\n",
    "            name += f\"{word}\"\n",
    "        if searchWhere == SearchWhere.Title:\n",
    "            name += \"_TitleOnly\"        \n",
    "        if searchWhere == SearchWhere.Abstract:\n",
    "            name += \"_TitleAbstract\"\n",
    "        if DEBUG > 0: driver.save_screenshot(f\"./acm_{name}.png\")\n",
    "        # get amount of results for for-loop\n",
    "        try:\n",
    "            results = driver.find_element_by_class_name(\"result__count\")\n",
    "            results = results.text.split(\" \")[0]\n",
    "            if \",\" in results:\n",
    "                results = results.replace(\",\", \"\")\n",
    "            results = int(results)\n",
    "        except NoSuchElementException:\n",
    "            results = 0\n",
    "        r = np.min([math.ceil(results / 50), acm_maxpage])\n",
    "        # Loop through all pages and save resulting bib files\n",
    "        for i in tqdm.tqdm(range(r)):\n",
    "            toOpen = ACM_URL + str(i)\n",
    "            driver = setupCrawler(dl_folder)\n",
    "            loadACMBib(toOpen, driver)\n",
    "            try:\n",
    "                os.rename('acm/acm.bib', f'acm/acm_{name}_page{i}.bib')\n",
    "            except FileNotFoundError:\n",
    "                print(\"Only 1 bib entry in that file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start crawling ACM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\AppData\\Local\\Temp\\ipykernel_45476\\2724785156.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = \"./chromedriver.exe\", options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver setup complete.\n",
      "Search for: ['selection', 'virtual']\n",
      "Searching ACM for title and abstract\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jan\\Documents\\GitHub\\MA-Leusmann-VRSelectionLiteratureReview\\PyLitReview_v2.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000012?line=0'>1</a>\u001b[0m crawl(keywords, \u001b[39m\"\u001b[39;49m\u001b[39mACM\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtitAbs\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Jan\\Documents\\GitHub\\MA-Leusmann-VRSelectionLiteratureReview\\PyLitReview_v2.ipynb Cell 7'\u001b[0m in \u001b[0;36mcrawl\u001b[1;34m(keywords_list, library, searchWhere)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000006?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m library \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mACM\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000006?line=25'>26</a>\u001b[0m     keywords \u001b[39m=\u001b[39m [[item\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m keywords] \u001b[39mfor\u001b[39;00m keywords \u001b[39min\u001b[39;00m keywords_list]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000006?line=26'>27</a>\u001b[0m     saveACMBib(keywords, \u001b[39m\"\u001b[39;49m\u001b[39macm\u001b[39;49m\u001b[39m\"\u001b[39;49m, searchWhere)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000006?line=27'>28</a>\u001b[0m \u001b[39melif\u001b[39;00m library \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mIEEE\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000006?line=28'>29</a>\u001b[0m     keywords \u001b[39m=\u001b[39m [[item\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39m20\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m keywords] \u001b[39mfor\u001b[39;00m keywords \u001b[39min\u001b[39;00m keywords_list]\n",
      "\u001b[1;32mc:\\Users\\Jan\\Documents\\GitHub\\MA-Leusmann-VRSelectionLiteratureReview\\PyLitReview_v2.ipynb Cell 12'\u001b[0m in \u001b[0;36msaveACMBib\u001b[1;34m(keywords_list, dl_folder, titleOnly)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000011?line=13'>14</a>\u001b[0m ACM_URL \u001b[39m=\u001b[39m getURL(keywords, \u001b[39m\"\u001b[39m\u001b[39mACM\u001b[39m\u001b[39m\"\u001b[39m, titleOnly)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000011?line=14'>15</a>\u001b[0m driver\u001b[39m.\u001b[39mget(ACM_URL)\u001b[39m#put here the adress of your page\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000011?line=15'>16</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m3\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000011?line=16'>17</a>\u001b[0m name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jan/Documents/GitHub/MA-Leusmann-VRSelectionLiteratureReview/PyLitReview_v2.ipynb#ch0000011?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m keywords:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crawl(keywords, \"ACM\", SearchWhere.TitleAbstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScienceDirect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loginScienceDirect(driver):\n",
    "    Login_URL = \"https://www.sciencedirect.com/\"\n",
    "    driver.get(Login_URL)\n",
    "    time.sleep(5)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"init.png\")\n",
    "    driver.find_element_by_link_text(\"Sign in\").click()\n",
    "    time.sleep(10)\n",
    "    mail = driver.find_element_by_id(\"bdd-email\")\n",
    "    mail.send_keys(UNI_MAIL)\n",
    "    time.sleep(1)\n",
    "    mail.send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"login.png\")\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_id(\"bdd-elsPrimaryBtn\").click()\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_id(\"username\").send_keys(UNI_USER)\n",
    "    time.sleep(1)\n",
    "    pwd = driver.find_element_by_id(\"password\")\n",
    "    pwd.send_keys(UNI_PWD)\n",
    "    time.sleep(1)\n",
    "    pwd.send_keys(Keys.ENTER)\n",
    "    time.sleep(2)\n",
    "    # attemps = 0\n",
    "    try:\n",
    "        driver.find_element_by_id(\"institution-button\").click()\n",
    "    except:\n",
    "        print(\"intitution button apparently no accessable\")\n",
    "        driver.save_screenshot(\"StaleElement.png\")\n",
    "        driver.find_element_by_id(\"institution-button\").click()\n",
    "    time.sleep(2)\n",
    "    return driver\n",
    "def loadScienceDirectBib(toOpen, driver):\n",
    "    driver.get(toOpen)\n",
    "    time.sleep(5)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"sciencedirect.png\")\n",
    "    driver.find_element_by_id(\"select-all-results\").click()\n",
    "    time.sleep(1)\n",
    "    if DEBUG > 1: driver.save_screenshot(\"sciencedirect_clickall.png\")\n",
    "    driver.find_element_by_class_name(\"button-link.export-all-link-button.button-link-primary\").click()\n",
    "    time.sleep(5)\n",
    "    driver.find_elements_by_class_name(\"button-link.button-link-primary.export-option.u-display-block\")[2].click()\n",
    "    time.sleep(10)\n",
    "def saveScienceDirectBib(keywords_list, dl_folder, titleOnly):\n",
    "    driver = setupCrawler(dl_folder)\n",
    "    SD_URL = getURL(keywords_list[0], \"ScienceDirect\", titleOnly)\n",
    "    driver.get('https://www.sciencedirect.com/')\n",
    "    if DEBUG > 1: driver.save_screenshot(\"SD.png\")\n",
    "    try:\n",
    "        driver = loginScienceDirect(driver)\n",
    "    except NoSuchElementException:\n",
    "        print(\"Already logged in or wrong credentials\") \n",
    "    # loginScienceDirect(driver)\n",
    "    if DEBUG > 1: driver.save_screenshot(f\"{SD_URL}.png\")\n",
    "    for keywords in keywords_list:\n",
    "        print(f\"Search for: {keywords}\")\n",
    "        SD_URL = getURL(keywords, \"ScienceDirect\", titleOnly)\n",
    "        driver.get(SD_URL)#put here the adress of your page\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            results = driver.find_element_by_class_name(\"search-body-results-text\")\n",
    "            results = results.text.split(\" \")[0]\n",
    "            if \",\" in results:\n",
    "                results = results.replace(\",\", \"\")\n",
    "            results = int(results)\n",
    "        except NoSuchElementException:\n",
    "            results = 0\n",
    "        \n",
    "        r = np.min([math.ceil(results / 50), sd_maxpage])\n",
    "        for i in tqdm.tqdm(range(r)):\n",
    "            # driver = setupCrawler(dl_folder)\n",
    "            toOpen = SD_URL + str(i*50)\n",
    "            loadScienceDirectBib(toOpen, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl(keywords, \"ScienceDirect\", SearchWhere.Title)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6532684ccaeb1bcbbe852b7f75c67e6f1d55df7d386020fd37670376cbe3d2c9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
